{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b56faf49f5da4d36a795be046a48f263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb0c88d995a14432956e0a2bb373ba12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99569fffc17647919b1c0506768dffc6",
              "IPY_MODEL_a205fcda37a340a3bbdc66a542a6c8b9"
            ]
          }
        },
        "bb0c88d995a14432956e0a2bb373ba12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99569fffc17647919b1c0506768dffc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b715e36f94414923b3bc7b68a41d76a8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80563c4e083e4896b180de4753cc3212"
          }
        },
        "a205fcda37a340a3bbdc66a542a6c8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_044a4cfd690c47a0b5bd6d040e398508",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [00:31&lt;00:00, 798.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00fb852331dd470bbb9a68edc6b91806"
          }
        },
        "b715e36f94414923b3bc7b68a41d76a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80563c4e083e4896b180de4753cc3212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "044a4cfd690c47a0b5bd6d040e398508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00fb852331dd470bbb9a68edc6b91806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beingraja/gan/blob/main/face_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77klgnDI4Djv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07788da-ff24-437e-9b3f-396625a61d17"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 27 18:08:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hnfguYA4SkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3912b9e3-de4a-4514-9b83-d4870277e0c8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5xQT3PT5QqV"
      },
      "source": [
        "!pip install -q kaggle\r\n",
        "!mkdir ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bVi2aUG5dfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff280f93-9bca-43d4-e889-9bdbf6ac63b5"
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading celeba-dataset.zip to /content\n",
            " 99% 1.32G/1.33G [00:25<00:00, 55.3MB/s]\n",
            "100% 1.33G/1.33G [00:25<00:00, 55.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N325kKGS5fkw"
      },
      "source": [
        "!unzip /content/celeba-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3607WPo153Cu"
      },
      "source": [
        "import os\r\n",
        "images = os.listdir('/content/img_align_celeba/img_align_celeba')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlnY8Jbq0Bt0"
      },
      "source": [
        "images = images[50000:75000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj_Mm7rMzDCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "b56faf49f5da4d36a795be046a48f263",
            "bb0c88d995a14432956e0a2bb373ba12",
            "99569fffc17647919b1c0506768dffc6",
            "a205fcda37a340a3bbdc66a542a6c8b9",
            "b715e36f94414923b3bc7b68a41d76a8",
            "80563c4e083e4896b180de4753cc3212",
            "044a4cfd690c47a0b5bd6d040e398508",
            "00fb852331dd470bbb9a68edc6b91806"
          ]
        },
        "outputId": "11bd4d54-c96f-4b5c-f247-c0c59f555272"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "import numpy as np\r\n",
        "import tqdm\r\n",
        "img_shape = (64, 64, 3)\r\n",
        "data_dir = '/content/img_align_celeba/img_align_celeba'\r\n",
        "def get_data(data_path) :\r\n",
        "    X = []\r\n",
        "    for filename in tqdm_notebook(data_path) :\r\n",
        "        img = img_to_array(load_img(data_dir + \"/\" + filename, target_size = img_shape[:2]))\r\n",
        "        X.append(img)\r\n",
        "    X = np.array(X).astype('float32')\r\n",
        "    #X = (X - 127.5) / 127.5\r\n",
        "    X = X / 255\r\n",
        "    return X\r\n",
        "\r\n",
        "X = get_data(images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b56faf49f5da4d36a795be046a48f263",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB4FIPD6z5Kn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "eb396922-1e21-489b-bd19-758ab30b095f"
      },
      "source": [
        "i = int(input('hello bitch'))\r\n",
        "plt.imshow(X[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3061b75b5b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello bitch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6BnRkmi57e1"
      },
      "source": [
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.layers import Dense , Reshape\r\n",
        "from tensorflow.keras.layers import Conv2D , Conv2DTranspose\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\r\n",
        "from numpy.random import randn\r\n",
        "from numpy.random import randint\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import imageio\r\n",
        "import os\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtsFgthh6daj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc5afa5-7f48-4d93-92ed-89d4ccd10c7f"
      },
      "source": [
        "def discriminator(in_shape = (64,64,3)):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(64,(3,3),strides=(2,2),padding='same', input_shape=in_shape))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.4))\r\n",
        "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same'))\r\n",
        "    #model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same', input_shape=in_shape))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    model.add(Dropout(0.4))\r\n",
        "    model.add(Dropout(0.4))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(1,activation='sigmoid'))\r\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\r\n",
        "    model.summary()\r\n",
        "    return model\r\n",
        "\r\n",
        "discriminator()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 8193      \n",
            "=================================================================\n",
            "Total params: 231,425\n",
            "Trainable params: 231,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3a6e544438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPcFZIHL8y7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f2978d-0189-4d5e-db49-b2e390ea6842"
      },
      "source": [
        "def generator(latent_dim):\r\n",
        "    n = 8 * 8* 128\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(n, input_dim=latent_dim))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))  \r\n",
        "\r\n",
        "    model.add(Reshape((8, 8, 128)))\r\n",
        "    model.add(Conv2DTranspose(128, (3,3), strides=(2,2), padding='same'))\r\n",
        "    #model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "    model.add(Conv2DTranspose(128, (3,3), strides=(2,2), padding='same'))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "    model.add(Conv2DTranspose(256, (3,3), strides=(2,2), padding='same'))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "    #model.add(BatchNormalization(momentum=0.8))\r\n",
        "    model.add(Conv2D(3, (7,7), activation='tanh', padding='same'))\r\n",
        "    model.summary()\r\n",
        "    return model \r\n",
        "generator(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8192)              827392    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 1,455,363\n",
            "Trainable params: 1,455,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3a602325f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU9wXZL4_LF3"
      },
      "source": [
        "def gan(discriminator , generator):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(generator)\r\n",
        "    discriminator.trainable = False\r\n",
        "    model.add(discriminator)\r\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\r\n",
        "    model.summary()\r\n",
        "    discriminator.trainable = True\r\n",
        "    return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97OmPNsJI6Uu"
      },
      "source": [
        "import os \r\n",
        "def generate_latent(batch_size = 128,latent_dim=100):\r\n",
        "    latent = randn(latent_dim*batch_size)\r\n",
        "    latent = np.reshape(latent,(batch_size,latent_dim))\r\n",
        "    return latent\r\n",
        "def generator_fake_samples(gen,latent_dim,batch_size = 128):\r\n",
        "    lat = generate_latent(batch_size=128,latent_dim=100)\r\n",
        "    X = gen.predict(lat)\r\n",
        "    y = np.zeros((batch_size,1))\r\n",
        "    return X,y\r\n",
        "def generate_real(data , batch_size = 128):\r\n",
        "    rand = randint(0,data.shape[0],batch_size)\r\n",
        "    X = data[rand]\r\n",
        "    y = np.ones((batch_size,1))\r\n",
        "    return X,y\r\n",
        "def save_images(gen,epoch,latent_dim,noise,size = 5):\r\n",
        "\r\n",
        "    gen_imgs = gen.predict(noise)\r\n",
        "    \r\n",
        "    # Rescale images 0 - 1\r\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\r\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images'\r\n",
        "    try:\r\n",
        "        os.mkdir('/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images')\r\n",
        "    except FileExistsError:\r\n",
        "        pass\r\n",
        "    fig, axs = plt.subplots(size, size)\r\n",
        "    cnt = 0\r\n",
        "    for i in range(size):\r\n",
        "        for j in range(size):\r\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\r\n",
        "            axs[i,j].axis('off')\r\n",
        "            cnt += 1\r\n",
        "    fig.savefig(\"/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images/images_%d.png\" % epoch)\r\n",
        "    plt.close()\r\n",
        "\r\n",
        "\r\n",
        "def save_model(gen,dis,combo,i,iv):\r\n",
        "\r\n",
        "    try:\r\n",
        "        os.mkdir('/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/models')\r\n",
        "    except FileExistsError:\r\n",
        "        pass\r\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/'\r\n",
        "    gen.save(path+'models/generator_epoch_'+ str(i)+'.h5') \r\n",
        "    dis.save(path+'models/discriminator_epoch_'+ str(i)+'.h5')   \r\n",
        "    combo.save(path+'models/gan_epoch_'+ str(i)+'.h5')     \r\n",
        "\r\n",
        "    if i > iv:\r\n",
        "        with open(path+'models/generator_epoch_'+ str(i-iv)+'.h5','w') as f:\r\n",
        "            f.close()\r\n",
        "        os.remove(path+'models/generator_epoch_'+ str(i-iv)+'.h5')\r\n",
        "        with open(path+'models/discriminator_epoch_'+ str(i-iv)+'.h5','w') as f:\r\n",
        "            f.close() \r\n",
        "        os.remove(path+'models/discriminator_epoch_'+ str(i-iv)+'.h5')\r\n",
        "        with open(path+'models/gan_epoch_'+ str(i-iv)+'.h5','w') as f:\r\n",
        "            f.close()\r\n",
        "        os.remove(path+'models/gan_epoch_'+ str(i-iv)+'.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdmvPo8oGCiM"
      },
      "source": [
        "def train( gen , dis, combo , data, model_save_interval, generated_images_interval ,epoch = 2 , batch_size = 128 ):\r\n",
        "    noise = np.random.normal(0, 1, (5 * 5, 100))\r\n",
        "    for i in range(epoch):\r\n",
        "        n_batch =int(data.shape[0] / batch_size)\r\n",
        "        for j in range(n_batch):\r\n",
        "            X_real,y_real = generate_real(data,batch_size=128)\r\n",
        "            X_fake,y_fake = generator_fake_samples(gen,100,batch_size)\r\n",
        "\r\n",
        "            #discriminator loss\r\n",
        "            dfake_loss , _ = dis.train_on_batch(X_fake,y_fake)\r\n",
        "            dreal_loss, _ = dis.train_on_batch(X_real,y_real)\r\n",
        "            d_loss = 0.5*np.add(dfake_loss,dreal_loss)\r\n",
        "\r\n",
        "            #for combined gan \r\n",
        "            latent = generate_latent(batch_size=128,latent_dim=100)\r\n",
        "            y_combo = np.ones((batch_size,1))\r\n",
        "            gan_loss = combo.train_on_batch(latent,y_combo)\r\n",
        "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i, j, n_batch, d_loss, gan_loss))\r\n",
        "\r\n",
        "        if i != 0 and i != 1 and i % model_save_interval == 0:\r\n",
        "            save_model(gen,dis,combo,i,model_save_interval)\r\n",
        "        if  i % generated_images_interval==0:\r\n",
        "            save_images(gen,i,100,noise,5)\r\n",
        "    return gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItmhFMzoeXNm"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "def run_model(load_saved = False):    \r\n",
        "    if load_saved == True:\r\n",
        "        i = 95\r\n",
        "        path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/'\r\n",
        "        gen = load_model(path+'models/generator_epoch_'+ str(i)+'.h5')\r\n",
        "        dis = load_model(path+'models/discriminator_epoch_'+ str(i)+'.h5')\r\n",
        "        dis.trainable = True\r\n",
        "        combo = gan(dis,gen)\r\n",
        "        dis.summary()\r\n",
        "        gen= train(gen,dis,combo,X,5,100)\r\n",
        "    else:\r\n",
        "        gen = generator(100)\r\n",
        "        dis = discriminator()\r\n",
        "        combo = gan(dis,gen)\r\n",
        "        gen = train(gen,dis,combo,X,5,1,epoch=100)\r\n",
        "    return gen\r\n",
        " \r\n",
        "gen = run_model(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCgXJhtNfJAU"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "import numpy as np\r\n",
        "noise = np.random.normal(0, 1, (1, 100))\r\n",
        "gen = load_model('/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/models/generator_epoch_95.h5')\r\n",
        "gen_imgs = gen.predict(noise)\r\n",
        "# Rescale images 0 - 1\r\n",
        "gen_imgs = np.array(0.5 * gen_imgs + 0.5).reshape((64,64,3))\r\n",
        "\r\n",
        "plt.imshow(gen_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAB5YDc189fR"
      },
      "source": [
        "def save_images():\r\n",
        "\r\n",
        "    gen_imgs = gen.predict(noise)\r\n",
        "\r\n",
        "    # Rescale images 0 - 1\r\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\r\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images'\r\n",
        "    try:\r\n",
        "        os.mkdir('/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images')\r\n",
        "    except FileExistsError:\r\n",
        "        pass\r\n",
        "    fig, axs = plt.subplots((size, size))\r\n",
        "    cnt = 0\r\n",
        "    for i in range(size):\r\n",
        "        for j in range(size):\r\n",
        "            axs[i,j].imshow(cv2.cvtColor(gen_imgs[cnt, :,:,0],cv2.COLOR_BGR2RGB))\r\n",
        "            axs[i,j].axis('off')\r\n",
        "            cnt += 1\r\n",
        "    \r\n",
        "    fig.savefig(\"/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images/images_%d.png\" % epoch)\r\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZHGIOh-xdjQ"
      },
      "source": [
        "import os\r\n",
        "l = os.listdir('/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_eazSIxjWm"
      },
      "source": [
        "import os\r\n",
        "import imageio\r\n",
        "\r\n",
        "png_dir ='/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/images'\r\n",
        "images = []\r\n",
        "for file_name in os.listdir(png_dir):\r\n",
        "    if file_name.endswith('.png'):\r\n",
        "        file_path = os.path.join(png_dir, file_name)\r\n",
        "        images.append(imageio.imread(file_path))\r\n",
        "imageio.mimsave('movie.gif', images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa7auCKjM37P"
      },
      "source": [
        "!!pip install tensorflow==2.1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLTsM7Y4N08x"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INWNSJNgxkKl"
      },
      "source": [
        "i = 95\r\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/'\r\n",
        "gen = load_model(path+'models/generator_epoch_'+ str(i)+'.h5')\r\n",
        "dis = load_model(path+'models/discriminator_epoch_'+ str(i)+'.h5')\r\n",
        "combo = load_model(path+'models/gan_epoch_'+ str(i)+'.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MEomvsNMBZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a471baee-1086-46f0-fddb-e34fc8243720"
      },
      "source": [
        "i = 95\r\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Untitled Folder/face_gan/'\r\n",
        "gen = load_model(path+'models/generator_epoch_'+ str(i)+'.h5')\r\n",
        "dis = load_model(path+'models/discriminator_epoch_'+ str(i)+'.h5')\r\n",
        "combo = load_model(path+'models/gan_epoch_'+ str(i)+'.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idZua4IVNmtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121ebc4c-cb47-4c4a-e4b1-f18929cdac14"
      },
      "source": [
        "\r\n",
        "dis.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_56 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_98 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_99 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_100 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 8193      \n",
            "=================================================================\n",
            "Total params: 231,425\n",
            "Trainable params: 0\n",
            "Non-trainable params: 231,425\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2_GJlw2vZol"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}